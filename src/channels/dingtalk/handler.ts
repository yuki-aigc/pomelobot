/**
 * DingTalk Message Handler
 * Handles incoming messages and agent interaction
 */

import crypto from 'node:crypto';
import { execFile as execFileCallback } from 'node:child_process';
import { promises as fsPromises } from 'node:fs';
import path from 'node:path';
import os from 'node:os';
import { promisify } from 'node:util';
import type { DingTalkConfig, CompactionConfig } from '../../config.js';
import type {
    DingTalkInboundMessage,
    MessageContent,
    SessionState,
    Logger,
    AICardInstance,
    AICardState,
} from './types.js';
import {
    sendBySession,
    createAICard,
    streamAICard,
    finishAICard,
    isCardFinished,
    getActiveAICard,
    cleanupCardCache,
    downloadMedia,
} from './client.js';
import { AICardStatus } from './types.js';
import { hasPendingApprovalForKey, tryHandleExecApprovalReply } from './approvals.js';
import {
    createMemoryFlushState,
    estimateTokens,
    updateTokenCount,
    shouldTriggerMemoryFlush,
    markFlushCompleted,
    isNoReplyResponse,
    MEMORY_FLUSH_SYSTEM_PROMPT,
    MEMORY_FLUSH_USER_PROMPT,
    type MemoryFlushState,
} from '../../middleware/index.js';
import {
    shouldAutoCompact,
    compactMessages,
    formatTokenCount,
    getContextUsageInfo,
} from '../../compaction/index.js';
import type { BaseChatModel } from '@langchain/core/language_models/chat_models';
import type { Config } from '../../config.js';
import {
    createChatModel,
    getActiveModelEntry,
    getActiveModelAlias,
    getModelCacheKey,
    listConfiguredModels,
} from '../../llm.js';
import { HumanMessage as LCHumanMessage } from '@langchain/core/messages';
import { withDingTalkConversationContext } from './context.js';

// Session state cache (conversationId -> SessionState)
const sessionCache = new Map<string, SessionState>();
let cachedCompactionModel: BaseChatModel | null = null;
let cachedCompactionModelKey = '';

// Per-conversation processing queue to ensure serial handling
const conversationQueue = new Map<string, Promise<void>>();

// Session TTL (2 hours)
const SESSION_TTL = 2 * 60 * 60 * 1000;
const MAX_TEXT_FILE_BYTES = 256 * 1024;
const MAX_TEXT_FILE_CHARS = 6000;
const MAX_IMAGE_BYTES = 8 * 1024 * 1024;
const MAX_VIDEO_FRAMES = 3;
const commandAvailabilityCache = new Map<string, boolean>();
const execFileAsync = promisify(execFileCallback);

const TEXT_MIME_HINTS = [
    'text/',
    'application/json',
    'application/xml',
    'application/yaml',
    'application/x-yaml',
    'application/javascript',
    'application/x-javascript',
    'application/csv',
];

const TEXT_FILE_EXTENSIONS = new Set([
    '.txt', '.md', '.markdown', '.json', '.yaml', '.yml', '.xml', '.csv', '.ts', '.tsx',
    '.js', '.jsx', '.mjs', '.cjs', '.py', '.go', '.java', '.rb', '.php', '.sql', '.sh',
    '.bash', '.zsh', '.ini', '.toml', '.conf', '.log', '.env',
]);

function enqueueConversationTask(
    conversationId: string,
    task: () => Promise<void>
): Promise<void> {
    const previous = conversationQueue.get(conversationId) ?? Promise.resolve();
    const next = previous.then(task, task).finally(() => {
        if (conversationQueue.get(conversationId) === next) {
            conversationQueue.delete(conversationId);
        }
    });
    conversationQueue.set(conversationId, next);
    return next;
}

/**
 * Extract message content from DingTalk message
 */
export function extractMessageContent(data: DingTalkInboundMessage): MessageContent {
    const msgtype = data.msgtype || 'text';

    if (msgtype === 'text') {
        return { text: data.text?.content?.trim() || '', messageType: 'text' };
    }

    if (msgtype === 'richText') {
        const richTextParts = data.content?.richText || [];
        let text = '';
        for (const part of richTextParts) {
            if (part.type === 'text' && part.text) text += part.text;
            if (part.type === 'at' && part.atName) text += `@${part.atName} `;
        }
        return { text: text.trim() || '[å¯Œæ–‡æœ¬æ¶ˆæ¯]', messageType: 'richText' };
    }

    if (msgtype === 'picture') {
        return { text: '[å›¾ç‰‡]', mediaPath: data.content?.downloadCode, mediaType: 'image', messageType: 'picture' };
    }

    if (msgtype === 'audio') {
        return {
            text: data.content?.recognition || '[è¯­éŸ³æ¶ˆæ¯]',
            mediaPath: data.content?.downloadCode,
            mediaType: 'audio',
            messageType: 'audio',
        };
    }

    if (msgtype === 'video') {
        return { text: '[è§†é¢‘]', mediaPath: data.content?.downloadCode, mediaType: 'video', messageType: 'video' };
    }

    if (msgtype === 'file') {
        return {
            text: `[æ–‡ä»¶: ${data.content?.fileName || 'æ–‡ä»¶'}]`,
            mediaPath: data.content?.downloadCode,
            mediaType: 'file',
            messageType: 'file',
        };
    }

    // Fallback
    return { text: data.text?.content?.trim() || `[${msgtype}æ¶ˆæ¯]`, messageType: msgtype };
}

/**
 * Get or create session state for a conversation
 */
function getOrCreateSession(conversationId: string): SessionState {
    const existing = sessionCache.get(conversationId);
    if (existing && Date.now() - existing.lastUpdated < SESSION_TTL) {
        return existing;
    }

    const newSession: SessionState = {
        threadId: `dingtalk-${conversationId}-${crypto.randomUUID().slice(0, 8)}`,
        messageHistory: [],
        totalTokens: 0,
        totalInputTokens: 0,
        totalOutputTokens: 0,
        compactionCount: 0,
        lastUpdated: Date.now(),
    };
    sessionCache.set(conversationId, newSession);
    return newSession;
}

/**
 * Clean up expired sessions
 */
function cleanupSessions(): void {
    const now = Date.now();
    for (const [id, session] of sessionCache.entries()) {
        if (now - session.lastUpdated > SESSION_TTL) {
            sessionCache.delete(id);
        }
    }
}

/**
 * Get or create a shared compaction model from config
 */
async function getCompactionModel(config: Config): Promise<BaseChatModel> {
    const modelKey = getModelCacheKey(config);

    if (cachedCompactionModel && cachedCompactionModelKey === modelKey) {
        return cachedCompactionModel;
    }

    cachedCompactionModel = await createChatModel(config, { temperature: 0 });

    cachedCompactionModelKey = modelKey;
    return cachedCompactionModel;
}

function normalizeMimeType(mimeType: string | undefined): string {
    if (!mimeType) return 'application/octet-stream';
    return mimeType.split(';')[0].trim().toLowerCase() || 'application/octet-stream';
}

function formatBytes(size: number): string {
    if (size < 1024) return `${size} B`;
    if (size < 1024 * 1024) return `${(size / 1024).toFixed(1)} KB`;
    if (size < 1024 * 1024 * 1024) return `${(size / (1024 * 1024)).toFixed(1)} MB`;
    return `${(size / (1024 * 1024 * 1024)).toFixed(1)} GB`;
}

function extractTextFromModelContent(content: unknown): string {
    if (typeof content === 'string') {
        return content.trim();
    }
    if (!Array.isArray(content)) {
        return '';
    }

    const chunks: string[] = [];
    for (const block of content) {
        if (typeof block === 'string') {
            chunks.push(block);
            continue;
        }
        if (!block || typeof block !== 'object') {
            continue;
        }
        const text = (block as { text?: unknown }).text;
        if (typeof text === 'string') {
            chunks.push(text);
        }
    }
    return chunks.join('\n').trim();
}

function looksLikeTextFile(filePath: string, mimeType: string): boolean {
    const ext = path.extname(filePath).toLowerCase();
    if (TEXT_FILE_EXTENSIONS.has(ext)) {
        return true;
    }
    return TEXT_MIME_HINTS.some((hint) => mimeType.startsWith(hint));
}

function looksBinary(buffer: Buffer): boolean {
    const sampleLength = Math.min(buffer.length, 4096);
    if (sampleLength === 0) return false;
    let suspicious = 0;

    for (let i = 0; i < sampleLength; i += 1) {
        const code = buffer[i];
        if (code === 0) {
            return true;
        }
        const isControl = code < 9 || (code > 13 && code < 32);
        if (isControl) {
            suspicious += 1;
        }
    }
    return suspicious / sampleLength > 0.15;
}

async function readFilePrefix(filePath: string, maxBytes: number): Promise<{ buffer: Buffer; truncated: boolean }> {
    const handle = await fsPromises.open(filePath, 'r');
    try {
        const stat = await handle.stat();
        const readSize = Math.min(stat.size, maxBytes);
        const buffer = Buffer.alloc(readSize);
        const { bytesRead } = await handle.read(buffer, 0, readSize, 0);
        return {
            buffer: buffer.subarray(0, bytesRead),
            truncated: stat.size > maxBytes,
        };
    } finally {
        await handle.close();
    }
}

async function checkCommandAvailable(command: string): Promise<boolean> {
    const cached = commandAvailabilityCache.get(command);
    if (cached !== undefined) {
        return cached;
    }

    let available = false;
    try {
        await execFileAsync(command, ['-version'], { timeout: 2000 });
        available = true;
    } catch {
        available = false;
    }
    commandAvailabilityCache.set(command, available);
    return available;
}

async function describeImagesWithModel(params: {
    config: Config;
    log: Logger;
    prompt: string;
    images: Array<{ imagePath: string; mimeType: string }>;
}): Promise<string | null> {
    const imageBlocks: Array<{ type: 'text'; text: string } | { type: 'image_url'; image_url: { url: string } }> = [
        { type: 'text', text: params.prompt },
    ];

    for (const image of params.images) {
        let imageBuffer: Buffer;
        try {
            imageBuffer = await fsPromises.readFile(image.imagePath);
        } catch (error) {
            params.log.warn(`[DingTalk] Failed to read image file ${image.imagePath}: ${String(error)}`);
            continue;
        }

        if (imageBuffer.length > MAX_IMAGE_BYTES) {
            params.log.warn(
                `[DingTalk] Skip image understanding for large image (${formatBytes(imageBuffer.length)}): ${image.imagePath}`
            );
            continue;
        }

        imageBlocks.push({
            type: 'image_url',
            image_url: {
                url: `data:${normalizeMimeType(image.mimeType)};base64,${imageBuffer.toString('base64')}`,
            },
        });
    }

    if (imageBlocks.length <= 1) {
        return null;
    }

    try {
        const model = await createChatModel(params.config, { temperature: 0 });
        const result = await model.invoke([new LCHumanMessage({ content: imageBlocks })]);
        const text = extractTextFromModelContent(result.content);
        return text || null;
    } catch (error) {
        params.log.warn(`[DingTalk] Media understanding failed: ${String(error)}`);
        return null;
    }
}

async function probeVideoDuration(filePath: string): Promise<number | null> {
    if (!(await checkCommandAvailable('ffprobe'))) {
        return null;
    }
    try {
        const { stdout } = await execFileAsync(
            'ffprobe',
            [
                '-v', 'error',
                '-show_entries', 'format=duration',
                '-of', 'default=noprint_wrappers=1:nokey=1',
                filePath,
            ],
            { timeout: 8000 }
        );
        const value = Number.parseFloat(stdout.trim());
        if (Number.isFinite(value) && value > 0) {
            return value;
        }
    } catch {
        // ignore probe failures
    }
    return null;
}

function buildVideoTimestamps(duration: number | null): number[] {
    if (!duration || duration <= 0) {
        return [1];
    }
    if (duration < 5) {
        return [Math.max(duration / 2, 0.5)];
    }

    const raw = [duration * 0.15, duration * 0.5, duration * 0.85];
    const deduped = new Set<string>();
    const result: number[] = [];
    for (const value of raw) {
        const normalized = Math.max(0.5, Math.min(duration - 0.5, value));
        const key = normalized.toFixed(2);
        if (deduped.has(key)) continue;
        deduped.add(key);
        result.push(normalized);
        if (result.length >= MAX_VIDEO_FRAMES) break;
    }
    return result.length > 0 ? result : [1];
}

async function extractVideoFrames(params: {
    videoPath: string;
    duration: number | null;
    log: Logger;
}): Promise<{ tempDir: string; framePaths: string[] } | null> {
    if (!(await checkCommandAvailable('ffmpeg'))) {
        return null;
    }

    const tempDir = await fsPromises.mkdtemp(path.join(os.tmpdir(), 'dingtalk-video-'));
    const framePaths: string[] = [];
    const timestamps = buildVideoTimestamps(params.duration);

    for (let i = 0; i < timestamps.length; i += 1) {
        const timestamp = timestamps[i];
        const framePath = path.join(tempDir, `frame_${i + 1}.jpg`);
        try {
            await execFileAsync(
                'ffmpeg',
                [
                    '-hide_banner',
                    '-loglevel', 'error',
                    '-ss', timestamp.toFixed(2),
                    '-i', params.videoPath,
                    '-frames:v', '1',
                    '-q:v', '3',
                    '-y',
                    framePath,
                ],
                { timeout: 15000 }
            );
            const stat = await fsPromises.stat(framePath);
            if (stat.size > 0) {
                framePaths.push(framePath);
            }
        } catch (error) {
            params.log.debug(`[DingTalk] Failed to extract video frame at ${timestamp.toFixed(2)}s: ${String(error)}`);
        }
    }

    if (framePaths.length === 0) {
        await fsPromises.rm(tempDir, { recursive: true, force: true });
        return null;
    }

    return { tempDir, framePaths };
}

async function buildMediaContext(params: {
    config: Config;
    content: MessageContent;
    mediaPath: string;
    mimeType: string;
    log: Logger;
}): Promise<string | null> {
    const mediaType = params.content.mediaType;
    if (mediaType !== 'image' && mediaType !== 'video' && mediaType !== 'file') {
        return null;
    }

    let statSize = 0;
    try {
        const stat = await fsPromises.stat(params.mediaPath);
        statSize = stat.size;
    } catch {
        return null;
    }

    const mimeType = normalizeMimeType(params.mimeType);
    const fileName = path.basename(params.mediaPath);
    const baseLines = [
        '[åª’ä½“ä¸Šä¸‹æ–‡]',
        `ç±»å‹: ${mediaType}`,
        `æ–‡ä»¶: ${fileName}`,
        `MIME: ${mimeType}`,
        `å¤§å°: ${formatBytes(statSize)}`,
        `æœ¬åœ°è·¯å¾„: ${params.mediaPath}`,
    ];

    if (mediaType === 'image') {
        const description = await describeImagesWithModel({
            config: params.config,
            log: params.log,
            prompt:
                'ä½ æ˜¯åª’ä½“è§£æå™¨ã€‚è¯·ç”¨ä¸­æ–‡ç®€æ´è¾“å‡ºï¼š1) åœºæ™¯ä¸ä¸»ä½“ 2) å…³é”®æ–‡å­—/OCR 3) ä¸ç”¨æˆ·é—®é¢˜å¯èƒ½ç›¸å…³çš„ä¿¡æ¯ã€‚ä¸è¦ç¼–é€ ã€‚',
            images: [{ imagePath: params.mediaPath, mimeType }],
        });
        baseLines.push(description ? `å›¾ç‰‡ç†è§£:\n${description}` : 'å›¾ç‰‡ç†è§£: æ— æ³•è‡ªåŠ¨è§£æï¼Œè¯·ç»“åˆè·¯å¾„è‡ªè¡Œå¤„ç†ã€‚');
        return baseLines.join('\n');
    }

    if (mediaType === 'file') {
        if (!looksLikeTextFile(params.mediaPath, mimeType)) {
            baseLines.push('æ–‡ä»¶è§£æ: è¯¥æ–‡ä»¶ä¸æ˜¯å¯ç›´æ¥è¯»å–çš„æ–‡æœ¬æ ¼å¼ï¼Œå·²ä¿ç•™å…ƒä¿¡æ¯ã€‚');
            return baseLines.join('\n');
        }

        try {
            const { buffer, truncated } = await readFilePrefix(params.mediaPath, MAX_TEXT_FILE_BYTES);
            if (looksBinary(buffer)) {
                baseLines.push('æ–‡ä»¶è§£æ: æ–‡ä»¶åŒ…å«äºŒè¿›åˆ¶å†…å®¹ï¼Œæ— æ³•ä½œä¸ºçº¯æ–‡æœ¬è¯»å–ã€‚');
                return baseLines.join('\n');
            }
            const raw = buffer.toString('utf-8').replace(/\u0000/g, '').trim();
            const snippet = raw.length > MAX_TEXT_FILE_CHARS ? `${raw.slice(0, MAX_TEXT_FILE_CHARS)}\n...(truncated)` : raw;
            const truncatedFlag = truncated || raw.length > MAX_TEXT_FILE_CHARS;
            const safeSnippet = snippet.replace(/<\/file>/gi, '</ file>');
            baseLines.push(`<file name="${fileName}" mime="${mimeType}" truncated="${truncatedFlag}">\n${safeSnippet}\n</file>`);
            return baseLines.join('\n');
        } catch (error) {
            params.log.warn(`[DingTalk] Failed to parse file ${params.mediaPath}: ${String(error)}`);
            baseLines.push('æ–‡ä»¶è§£æ: è¯»å–å¤±è´¥ï¼Œå·²ä¿ç•™å…ƒä¿¡æ¯ã€‚');
            return baseLines.join('\n');
        }
    }

    const duration = await probeVideoDuration(params.mediaPath);
    if (duration) {
        baseLines.push(`æ—¶é•¿: ${duration.toFixed(1)}s`);
    }

    let extracted: { tempDir: string; framePaths: string[] } | null = null;
    try {
        extracted = await extractVideoFrames({
            videoPath: params.mediaPath,
            duration,
            log: params.log,
        });

        if (!extracted) {
            baseLines.push('è§†é¢‘ç†è§£: å½“å‰ç¯å¢ƒæœªæä¾› ffmpeg/ffprobe æˆ–æŠ½å¸§å¤±è´¥ï¼Œå·²ä¿ç•™å…ƒä¿¡æ¯ã€‚');
            return baseLines.join('\n');
        }

        const description = await describeImagesWithModel({
            config: params.config,
            log: params.log,
            prompt: 'ä½ ä¼šæ”¶åˆ°åŒä¸€æ®µè§†é¢‘çš„å¤šå¸§æˆªå›¾ã€‚è¯·ç”¨ä¸­æ–‡è¾“å‡ºè§†é¢‘å†…å®¹æ‘˜è¦ã€å…³é”®åŠ¨ä½œå’Œæ˜æ˜¾æ–‡å­—ä¿¡æ¯ã€‚ä¸è¦ç¼–é€ ã€‚',
            images: extracted.framePaths.map((framePath) => ({
                imagePath: framePath,
                mimeType: 'image/jpeg',
            })),
        });

        baseLines.push(`æŠ½å¸§: ${extracted.framePaths.length} å¸§`);
        baseLines.push(description ? `è§†é¢‘ç†è§£:\n${description}` : 'è§†é¢‘ç†è§£: æŠ½å¸§æˆåŠŸï¼Œä½†æ¨¡å‹æœªè¿”å›æœ‰æ•ˆæè¿°ã€‚');
        return baseLines.join('\n');
    } finally {
        if (extracted) {
            await fsPromises.rm(extracted.tempDir, { recursive: true, force: true }).catch(() => undefined);
        }
    }
}

export interface MessageHandlerContext {
    // eslint-disable-next-line @typescript-eslint/no-explicit-any
    agent: any;
    config: Config;
    dingtalkConfig: DingTalkConfig;
    log: Logger;
    switchModel?: (alias: string) => Promise<{ alias: string; model: string }>;
}

type ModelSlashCommand = { type: 'list' } | { type: 'switch'; alias: string };

type VoiceSlashCommand =
    | { type: 'voice'; mode: 'status' }
    | { type: 'voice'; mode: 'toggle'; enabled: boolean };

type SlashCommand = ModelSlashCommand | { type: 'status' } | VoiceSlashCommand;

interface VoiceInputConfig {
    enabled: boolean;
    requireRecognition: boolean;
    prependRecognitionHint: boolean;
}

function resolveVoiceInputConfig(config: DingTalkConfig): VoiceInputConfig {
    const voice = config.voice;
    return {
        enabled: voice?.enabled ?? true,
        requireRecognition: voice?.requireRecognition ?? true,
        prependRecognitionHint: voice?.prependRecognitionHint ?? true,
    };
}

function parseSlashCommand(input: string): SlashCommand | null {
    const text = input.trim();
    if (text === '/models') {
        return { type: 'list' };
    }
    if (text === '/status') {
        return { type: 'status' };
    }
    if (text === '/model') {
        return { type: 'switch', alias: '' };
    }
    if (text.startsWith('/model ')) {
        return { type: 'switch', alias: text.slice('/model'.length).trim() };
    }
    if (text === '/voice') {
        return { type: 'voice', mode: 'status' };
    }
    if (text.startsWith('/voice ')) {
        const arg = text.slice('/voice'.length).trim().toLowerCase();
        if (arg === 'on') {
            return { type: 'voice', mode: 'toggle', enabled: true };
        }
        if (arg === 'off') {
            return { type: 'voice', mode: 'toggle', enabled: false };
        }
        return { type: 'voice', mode: 'status' };
    }
    return null;
}

function maskApiKey(apiKey: string): string {
    if (!apiKey) return '(not set)';
    if (apiKey.length <= 8) return `${apiKey.slice(0, 2)}...${apiKey.slice(-2)}`;
    return `${apiKey.slice(0, 6)}...${apiKey.slice(-6)}`;
}

function formatRelativeTime(updatedAt: number): string {
    const diffMs = Math.max(0, Date.now() - updatedAt);
    const diffSec = Math.floor(diffMs / 1000);
    if (diffSec < 5) return 'just now';
    if (diffSec < 60) return `${diffSec}s ago`;
    if (diffSec < 3600) return `${Math.floor(diffSec / 60)}m ago`;
    if (diffSec < 86400) return `${Math.floor(diffSec / 3600)}h ago`;
    return `${Math.floor(diffSec / 86400)}d ago`;
}

function buildStatusMessage(params: {
    config: Config;
    session: SessionState;
}): string {
    const { config, session } = params;
    const activeAlias = getActiveModelAlias(config);
    const activeModel = getActiveModelEntry(config);
    const contextConfig = config.agent.compaction;
    const appVersion = process.env.npm_package_version || '1.0.0';
    const contextRatio = (session.totalTokens / contextConfig.context_window) * 100;
    const contextPercent = contextRatio >= 1
        ? Math.round(contextRatio)
        : Number(contextRatio.toFixed(1));

    return `ğŸ¤– SRE Bot ${appVersion}
ğŸ§  Model: ${activeModel.provider}/${activeModel.model} Â· ğŸ”‘ api-key ${maskApiKey(activeModel.api_key)} (${activeModel.provider}:${activeAlias})
ğŸ§® Tokens: ${formatTokenCount(session.totalInputTokens)} in / ${formatTokenCount(session.totalOutputTokens)} out
ğŸ“š Context: ${formatTokenCount(session.totalTokens)}/${formatTokenCount(contextConfig.context_window)} (${contextPercent}%) Â· ğŸ§¹ Compactions: ${session.compactionCount}
ğŸ§µ Session: ${session.threadId} â€¢ updated ${formatRelativeTime(session.lastUpdated)}
âš™ï¸ Runtime: dingtalk Â· Think: low
ğŸª¢ Queue: collect (depth 0)

${getContextUsageInfo(session.totalTokens, contextConfig)}
è‡ªåŠ¨å‹ç¼©é˜ˆå€¼: ${formatTokenCount(contextConfig.auto_compact_threshold)}`;
}

async function tryHandleSlashCommand(params: {
    text: string;
    ctx: MessageHandlerContext;
    session: SessionState;
    sessionWebhook: string;
    isDirect: boolean;
    senderId: string;
}): Promise<boolean> {
    const parsed = parseSlashCommand(params.text);
    if (!parsed) return false;

    const mention = { atUserId: !params.isDirect ? params.senderId : null };
    if (parsed.type === 'status') {
        const message = buildStatusMessage({
            config: params.ctx.config,
            session: params.session,
        });
        await sendBySession(params.ctx.dingtalkConfig, params.sessionWebhook, message, mention, params.ctx.log);
        return true;
    }

    if (parsed.type === 'voice') {
        const voiceConfig = resolveVoiceInputConfig(params.ctx.dingtalkConfig);
        if (parsed.mode === 'toggle') {
            params.ctx.dingtalkConfig.voice = {
                ...(params.ctx.dingtalkConfig.voice || {}),
                enabled: parsed.enabled,
            };
        }
        const current = resolveVoiceInputConfig(params.ctx.dingtalkConfig);
        const text = parsed.mode === 'toggle'
            ? `âœ… è¯­éŸ³è¾“å…¥å·²${parsed.enabled ? 'å¼€å¯' : 'å…³é—­'}ã€‚\n` +
            `è¯†åˆ«æ–‡æœ¬å¿…éœ€: ${current.requireRecognition ? 'æ˜¯' : 'å¦'}\n` +
            `è½¬å†™æç¤ºå‰ç¼€: ${current.prependRecognitionHint ? 'å¼€å¯' : 'å…³é—­'}\n` +
            'æç¤º: /voice on æˆ– /voice off å¯å®æ—¶åˆ‡æ¢'
            : `ğŸ¤ è¯­éŸ³è¾“å…¥çŠ¶æ€: ${voiceConfig.enabled ? 'å¼€å¯' : 'å…³é—­'}\n` +
            `è¯†åˆ«æ–‡æœ¬å¿…éœ€: ${voiceConfig.requireRecognition ? 'æ˜¯' : 'å¦'}\n` +
            `è½¬å†™æç¤ºå‰ç¼€: ${voiceConfig.prependRecognitionHint ? 'å¼€å¯' : 'å…³é—­'}\n` +
            'æç¤º: /voice on æˆ– /voice off å¯å®æ—¶åˆ‡æ¢';
        await sendBySession(params.ctx.dingtalkConfig, params.sessionWebhook, text, mention, params.ctx.log);
        return true;
    }

    if (parsed.type === 'list') {
        const activeAlias = getActiveModelAlias(params.ctx.config);
        const lines = listConfiguredModels(params.ctx.config)
            .map((item) => `${item.alias === activeAlias ? 'â€¢' : ' '} ${item.alias} (${item.provider}) -> ${item.model}`)
            .join('\n');
        const message = lines
            ? `ğŸ¤– å·²é…ç½®æ¨¡å‹\n\n${lines}`
            : 'â„¹ï¸ å½“å‰æ²¡æœ‰å¯ç”¨æ¨¡å‹é…ç½®ã€‚';
        await sendBySession(params.ctx.dingtalkConfig, params.sessionWebhook, message, mention, params.ctx.log);
        return true;
    }

    if (!parsed.alias) {
        await sendBySession(
            params.ctx.dingtalkConfig,
            params.sessionWebhook,
            `â„¹ï¸ ç”¨æ³•: /model <æ¨¡å‹åˆ«å>\nå½“å‰æ¨¡å‹: ${getActiveModelAlias(params.ctx.config)}`,
            mention,
            params.ctx.log
        );
        return true;
    }

    if (!params.ctx.switchModel) {
        await sendBySession(
            params.ctx.dingtalkConfig,
            params.sessionWebhook,
            'âŒ å½“å‰è¿è¡Œæ¨¡å¼ä¸æ”¯æŒå®æ—¶åˆ‡æ¢æ¨¡å‹ã€‚',
            mention,
            params.ctx.log
        );
        return true;
    }

    try {
        const result = await params.ctx.switchModel(parsed.alias);
        await sendBySession(
            params.ctx.dingtalkConfig,
            params.sessionWebhook,
            `âœ… å·²åˆ‡æ¢æ¨¡å‹: ${result.alias} (${result.model})`,
            mention,
            params.ctx.log
        );
    } catch (error) {
        await sendBySession(
            params.ctx.dingtalkConfig,
            params.sessionWebhook,
            `âŒ åˆ‡æ¢æ¨¡å‹å¤±è´¥: ${error instanceof Error ? error.message : String(error)}`,
            mention,
            params.ctx.log
        );
    }
    return true;
}

function preprocessAudioMessage(params: {
    config: DingTalkConfig;
    data: DingTalkInboundMessage;
    content: MessageContent;
}): { ok: true } | { ok: false; reason: string } {
    if (params.content.messageType !== 'audio') {
        return { ok: true };
    }

    const voiceConfig = resolveVoiceInputConfig(params.config);
    if (!voiceConfig.enabled) {
        return {
            ok: false,
            reason: 'ğŸ¤ å½“å‰ä¼šè¯æœªå¼€å¯è¯­éŸ³è¾“å…¥ï¼Œå‘é€ `/voice on` åå†è¯•ã€‚',
        };
    }

    const recognized = (params.data.content?.recognition || '').trim();
    if (!recognized) {
        if (voiceConfig.requireRecognition) {
            return {
                ok: false,
                reason: 'âŒ æœªè·å–åˆ°è¯­éŸ³è¯†åˆ«æ–‡æœ¬ã€‚è¯·åœ¨é’‰é’‰ä¾§å¼€å¯è¯­éŸ³è½¬æ–‡å­—ï¼Œæˆ–ç›´æ¥å‘é€æ–‡å­—æ¶ˆæ¯ã€‚',
            };
        }
        params.content.text = '[è¯­éŸ³æ¶ˆæ¯]';
        return { ok: true };
    }

    const normalized = recognized.replace(/\s+/g, ' ').trim();
    params.content.text = voiceConfig.prependRecognitionHint
        ? `ã€ç”¨æˆ·è¯­éŸ³è½¬å†™ã€‘${normalized}`
        : normalized;

    return { ok: true };
}

/**
 * Handle incoming DingTalk message
 */
export async function handleMessage(
    data: DingTalkInboundMessage,
    ctx: MessageHandlerContext
): Promise<void> {
    const senderId = data.senderStaffId || data.senderId;
    const senderName = data.senderNick || 'Unknown';
    const isDirect = data.conversationType === '1';
    return enqueueConversationTask(data.conversationId, () =>
        withDingTalkConversationContext(
            {
                conversationId: data.conversationId,
                isDirect,
                senderId,
                senderName,
                sessionWebhook: data.sessionWebhook,
            },
            () => handleMessageInternal(data, ctx)
        )
    );
}

async function handleMessageInternal(
    data: DingTalkInboundMessage,
    ctx: MessageHandlerContext
): Promise<void> {
    const { config, dingtalkConfig, log } = ctx;

    // Clean up expired sessions periodically
    cleanupSessions();
    cleanupCardCache();

    // Ignore bot self-messages
    if (data.senderId === data.chatbotUserId || data.senderStaffId === data.chatbotUserId) {
        log.debug('[DingTalk] Ignoring robot self-message');
        return;
    }

    // Extract message content
    const content = extractMessageContent(data);
    if (!content.text) {
        log.debug('[DingTalk] Empty message content, ignoring');
        return;
    }

    const isDirect = data.conversationType === '1';
    const senderId = data.senderStaffId || data.senderId;
    const senderName = data.senderNick || 'Unknown';
    const conversationId = data.conversationId;

    // Get or create session for this conversation
    const session = getOrCreateSession(conversationId);

    const handledModelCommand = await tryHandleSlashCommand({
        text: content.text,
        ctx,
        session,
        sessionWebhook: data.sessionWebhook,
        isDirect,
        senderId,
    });
    if (handledModelCommand) {
        return;
    }

    const audioPreprocess = preprocessAudioMessage({
        config: dingtalkConfig,
        data,
        content,
    });
    if (!audioPreprocess.ok) {
        await sendBySession(
            dingtalkConfig,
            data.sessionWebhook,
            audioPreprocess.reason,
            { atUserId: !isDirect ? senderId : null },
            log
        );
        return;
    }

    let downloadedMediaPath: string | undefined;
    if (content.mediaPath && dingtalkConfig.robotCode) {
        const media = await downloadMedia(dingtalkConfig, content.mediaPath, log);
        if (media) {
            downloadedMediaPath = media.path;
            const mediaNote = `[åª’ä½“æ–‡ä»¶å·²ä¸‹è½½: ${media.path} (${media.mimeType})]`;
            const mediaContext = await buildMediaContext({
                config,
                content,
                mediaPath: media.path,
                mimeType: media.mimeType,
                log,
            });
            const appendix = mediaContext ? `${mediaNote}\n${mediaContext}` : mediaNote;
            content.text = content.text ? `${content.text}\n\n${appendix}` : appendix;
        }
    }

    // Handle exec approval replies before normal processing
    const approvalHandled = await tryHandleExecApprovalReply({
        text: content.text,
        conversationId,
        senderId,
        sessionWebhook: data.sessionWebhook,
        isDirect,
        dingtalkConfig,
        log,
    });
    if (approvalHandled) {
        return;
    }

    // If there is a pending approval in this conversation, block new requests.
    if (hasPendingApprovalForKey(conversationId, senderId)) {
        await sendBySession(
            dingtalkConfig,
            data.sessionWebhook,
            'â³ å½“å‰æœ‰å¾…å¤„ç†çš„å®¡æ‰¹ï¼Œè¯·å…ˆå®Œæˆå®¡æ‰¹åå†å‘é€æ–°è¯·æ±‚ã€‚',
            { atUserId: !isDirect ? senderId : null },
            log
        );
        return;
    }

    log.info(`[DingTalk] Received message from ${senderName}: "${content.text.slice(0, 50)}${content.text.length > 50 ? '...' : ''}"`);

    // Create flush state from session
    let flushState: MemoryFlushState = createMemoryFlushState();
    flushState = { ...flushState, totalTokens: session.totalTokens };

    // Update token count with user input
    flushState = updateTokenCount(flushState, content.text);
    session.totalInputTokens += estimateTokens(content.text);

    // Reuse shared compaction model
    const compactionModel = await getCompactionModel(config);
    const compactionConfig = config.agent.compaction;

    // Check if we need auto-compaction before processing
    await executeAutoCompact(ctx.agent, session, flushState, compactionModel, compactionConfig, log);

    // Determine message mode
    const useCardMode = dingtalkConfig.messageType === 'card';
    let currentCard: AICardInstance | null = null;

    // Create or reuse AI Card if in card mode
    if (useCardMode) {
        const targetKey = isDirect ? senderId : conversationId;
        currentCard = getActiveAICard(targetKey) || null;
        if (currentCard) {
            log.info('[DingTalk] Reusing active AI Card for this conversation...');
        } else {
            log.info('[DingTalk] Card mode enabled, creating AI Card...');
            currentCard = await createAICard(
                dingtalkConfig,
                conversationId,
                isDirect,
                senderId,
                log
            );
            if (!currentCard) {
                log.warn('[DingTalk] Failed to create AI Card, falling back to markdown mode');
            } else {
                log.info('[DingTalk] AI Card created, proceeding with streaming...');
            }
        }
    }

    // Send "thinking" feedback (only for markdown mode, card mode shows thinking state visually)
    if (!currentCard && dingtalkConfig.showThinking !== false) {
        try {
            await sendBySession(
                dingtalkConfig,
                data.sessionWebhook,
                'ğŸ¤” æ€è€ƒä¸­ï¼Œè¯·ç¨å€™...',
                { atUserId: !isDirect ? senderId : null },
                log
            );
        } catch (err) {
            log.debug('[DingTalk] Failed to send thinking message:', String(err));
        }
    }

    try {
        // Invoke agent with streaming for card mode
        const agentConfig = {
            configurable: { thread_id: session.threadId },
            recursionLimit: config.agent.recursion_limit,
        };

        log.debug(`[DingTalk] Invoking agent with thread_id: ${session.threadId}`);

        let fullResponse = '';

        if (currentCard) {
            // Card mode: use streaming
            log.info('[DingTalk] Starting streamEvents...');

            const eventStream = ctx.agent.streamEvents(
                { messages: [{ role: 'user', content: content.text }] },
                { ...agentConfig, version: 'v2' }
            );

            log.info('[DingTalk] EventStream created, waiting for events...');

            let lastStreamTime = Date.now();
            const STREAM_THROTTLE = 500; // Minimum ms between stream updates
            const STREAM_MIN_CHARS = 40; // Minimum chars between updates
            let eventCount = 0;
            let lastFlushedLength = 0;
            let pendingFlush: NodeJS.Timeout | null = null;
            let flushInFlight = false;
            let flushQueuedFinal = false;
            let streamFlushError: unknown = null;

            const markStreamError = (err: unknown) => {
                if (!streamFlushError) {
                    streamFlushError = err;
                }
            };

            const flushNow = async (final: boolean) => {
                if (flushInFlight || !currentCard) {
                    flushQueuedFinal = flushQueuedFinal || final;
                    return;
                }
                const currentLength = fullResponse.length;
                if (!final && currentLength - lastFlushedLength < STREAM_MIN_CHARS) {
                    return;
                }
                flushInFlight = true;
                try {
                    await streamAICard(currentCard, fullResponse, final, dingtalkConfig, log);
                    lastStreamTime = Date.now();
                    lastFlushedLength = fullResponse.length;
                } catch (streamErr) {
                    markStreamError(streamErr);
                    log.warn('[DingTalk] Card stream update failed:', String(streamErr));
                } finally {
                    flushInFlight = false;
                    if (flushQueuedFinal) {
                        flushQueuedFinal = false;
                        await flushNow(true);
                    }
                }
            };

            const scheduleFlush = (final: boolean = false) => {
                if (final) flushQueuedFinal = true;
                if (pendingFlush) return;
                const now = Date.now();
                const delay = Math.max(0, STREAM_THROTTLE - (now - lastStreamTime));
                pendingFlush = setTimeout(() => {
                    pendingFlush = null;
                    void flushNow(final);
                }, delay);
            };

            for await (const event of eventStream) {
                eventCount++;
                if (eventCount <= 3 || eventCount % 10 === 0) {
                    log.debug(`[DingTalk] Event #${eventCount}: ${event.event}`);
                }

                if (event.event === 'on_chat_model_stream') {
                    const chunk = event.data?.chunk;
                    if (chunk?.content) {
                        let text = '';
                        if (typeof chunk.content === 'string') {
                            text = chunk.content;
                        } else if (Array.isArray(chunk.content)) {
                            for (const item of chunk.content) {
                                if (item.type === 'text' && item.text) {
                                    text += item.text;
                                }
                            }
                        }

                        fullResponse += text;

                        // Throttle stream updates to avoid rate limiting
                        scheduleFlush(false);
                    }
                } else if (event.event === 'on_tool_start') {
                    const toolName = event.name;
                    log.info(`[DingTalk] Tool started: ${toolName}`);
                    fullResponse += `\n[è°ƒç”¨å·¥å…·: ${toolName}]\n`;
                    scheduleFlush(false);
                }
            }

            log.info(`[DingTalk] Stream completed, total events: ${eventCount}, response length: ${fullResponse.length}`);

            // Finalize card
            let shouldFallbackToSessionMessage = false;
            if (fullResponse) {
                log.info('[DingTalk] Finalizing AI Card...');
                if (pendingFlush) {
                    clearTimeout(pendingFlush);
                    pendingFlush = null;
                }
                await flushNow(true);

                const cardState = currentCard.state as AICardState;
                if (streamFlushError || cardState !== AICardStatus.FINISHED) {
                    shouldFallbackToSessionMessage = true;
                    log.warn(
                        `[DingTalk] Card finalization incomplete (state=${cardState}), falling back to session markdown reply`
                    );
                } else {
                    log.info('[DingTalk] AI Card finalized successfully');
                }
            } else {
                log.warn('[DingTalk] No response content to send');
                fullResponse = 'æŠ±æ­‰ï¼Œæˆ‘æš‚æ—¶æ²¡æœ‰ç”Ÿæˆæœ‰æ•ˆå›å¤ï¼Œè¯·ç¨åé‡è¯•ã€‚';
                shouldFallbackToSessionMessage = true;
            }

            if (shouldFallbackToSessionMessage) {
                await sendBySession(
                    dingtalkConfig,
                    data.sessionWebhook,
                    fullResponse,
                    {
                        useMarkdown: true,
                        atUserId: !isDirect ? senderId : null,
                    },
                    log
                );
            }
        } else {
            // Markdown mode: use invoke
            const result = await ctx.agent.invoke(
                { messages: [{ role: 'user', content: content.text }] },
                agentConfig
            );

            // Extract response
            const messages = result.messages;
            if (Array.isArray(messages) && messages.length > 0) {
                const lastMessage = messages[messages.length - 1];
                fullResponse = typeof lastMessage.content === 'string'
                    ? lastMessage.content
                    : JSON.stringify(lastMessage.content);
            }

            if (!fullResponse) {
                fullResponse = 'æŠ±æ­‰ï¼Œæˆ‘æ²¡æœ‰ç”Ÿæˆæœ‰æ•ˆçš„å›å¤ã€‚';
            }

            // Send response back to DingTalk
            log.info(`[DingTalk] Sending response (${fullResponse.length} chars) to ${senderName}`);

            await sendBySession(
                dingtalkConfig,
                data.sessionWebhook,
                fullResponse,
                {
                    useMarkdown: true,
                    atUserId: !isDirect ? senderId : null,
                },
                log
            );
        }

        // Update token count and message history
        flushState = updateTokenCount(flushState, fullResponse);
        session.totalOutputTokens += estimateTokens(fullResponse);
        const { HumanMessage, AIMessage } = await import('@langchain/core/messages');
        session.messageHistory.push(new HumanMessage(content.text));
        session.messageHistory.push(new AIMessage(fullResponse));
        session.totalTokens = flushState.totalTokens;
        session.lastUpdated = Date.now();

        // Check auto-compaction after response
        await executeAutoCompact(ctx.agent, session, flushState, compactionModel, compactionConfig, log);

    } catch (error) {
        const errorMessage = error instanceof Error ? error.message : String(error);
        log.error(`[DingTalk] Error processing message: ${errorMessage}`);
        const err = error as {
            name?: string;
            code?: string;
            status?: number;
            response?: { status?: number; data?: unknown; config?: { url?: string; method?: string } };
            config?: { url?: string; method?: string };
            stack?: string;
        };
        const safeStringify = (value: unknown) => {
            try {
                return JSON.stringify(value);
            } catch {
                return '"[unserializable]"';
            }
        };
        const cause = (err as { cause?: unknown })?.cause;
        log.error(
            `[DingTalk] Error details: ${safeStringify({
                name: err?.name,
                code: err?.code,
                status: err?.status ?? err?.response?.status,
                url: err?.response?.config?.url || err?.config?.url,
                method: err?.response?.config?.method || err?.config?.method,
                data: err?.response?.data,
                cause: cause && typeof cause === 'object' ? cause : String(cause ?? ''),
                stack: err?.stack ? err.stack.split('\n').slice(0, 3).join(' | ') : undefined,
            })}`
        );

        // If card mode failed, try to finalize with error
        if (currentCard && !isCardFinished(currentCard)) {
            try {
                await finishAICard(currentCard, `âŒ å¤„ç†å‡ºé”™: ${errorMessage}`, dingtalkConfig, log);
            } catch (finishErr) {
                log.debug('[DingTalk] Failed to finalize error card:', String(finishErr));
            }
        }

        try {
            await sendBySession(
                dingtalkConfig,
                data.sessionWebhook,
                `âŒ å¤„ç†æ¶ˆæ¯æ—¶å‡ºé”™: ${errorMessage}`,
                { atUserId: !isDirect ? senderId : null },
                log
            );
        } catch (sendErr) {
            log.error('[DingTalk] Failed to send error message:', String(sendErr));
        }
    } finally {
        if (downloadedMediaPath) {
            try {
                await import('node:fs/promises').then((fsPromises) => fsPromises.unlink(downloadedMediaPath));
            } catch {
                // ignore cleanup errors
            }
        }
    }
}

/**
 * Execute memory flush
 */
async function executeMemoryFlush(
    // eslint-disable-next-line @typescript-eslint/no-explicit-any
    agent: any,
    session: SessionState,
    flushState: MemoryFlushState,
    log: Logger
): Promise<MemoryFlushState> {
    log.info('[DingTalk] Executing memory flush...');

    try {
        const result = await agent.invoke(
            {
                messages: [
                    { role: 'system', content: MEMORY_FLUSH_SYSTEM_PROMPT },
                    { role: 'user', content: MEMORY_FLUSH_USER_PROMPT },
                ],
            },
            {
                configurable: { thread_id: session.threadId },
                recursionLimit: 10,
            }
        );

        const messages = result.messages;
        if (Array.isArray(messages) && messages.length > 0) {
            const lastMessage = messages[messages.length - 1];
            const content = typeof lastMessage.content === 'string' ? lastMessage.content : '';
            if (isNoReplyResponse(content)) {
                log.debug('[DingTalk] Memory flush completed (no reply needed)');
            } else {
                log.debug('[DingTalk] Memory flush completed');
            }
        }

        return markFlushCompleted(flushState);
    } catch (error) {
        log.error('[DingTalk] Memory flush failed:', String(error));
        return flushState;
    }
}

/**
 * Execute auto-compaction if needed
 */
async function executeAutoCompact(
    // eslint-disable-next-line @typescript-eslint/no-explicit-any
    agent: any,
    session: SessionState,
    flushState: MemoryFlushState,
    compactionModel: BaseChatModel,
    compactionConfig: CompactionConfig,
    log: Logger
): Promise<void> {
    if (!shouldAutoCompact(flushState.totalTokens, compactionConfig)) {
        return;
    }

    log.info('[DingTalk] Auto-compacting context...');

    // First: flush memory to save important info
    if (shouldTriggerMemoryFlush(flushState, compactionConfig)) {
        flushState = await executeMemoryFlush(agent, session, flushState, log);
    }

    // Then: compact context
    try {
        const maxTokens = Math.floor(compactionConfig.context_window * compactionConfig.max_history_share);
        const result = await compactMessages(session.messageHistory, compactionModel, maxTokens);

        session.messageHistory = result.messages;
        session.totalTokens = result.tokensAfter;
        session.compactionCount += 1;

        const saved = result.tokensBefore - result.tokensAfter;
        log.info(`[DingTalk] Compaction completed, saved ${formatTokenCount(saved)} tokens`);
    } catch (error) {
        log.error('[DingTalk] Compaction failed:', String(error));
    }
}
